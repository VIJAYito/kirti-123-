{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd7c3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kirtisailinaidu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "484c488e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/kirtisailinaidu/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b54e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: nltk>=3.8 in ./anaconda3/lib/python3.11/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in ./anaconda3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in ./anaconda3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./anaconda3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.11/site-packages (from nltk>=3.8->textblob) (4.65.0)\n",
      "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.3/626.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: textblob\n",
      "Successfully installed textblob-0.18.0.post0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e3c26fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirtisailinaidu/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "090258f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
       "0      T     2     8      3       5      1     8    13      0      6      6   \n",
       "1      I     5    12      3       7      2    10     5      5      4     13   \n",
       "2      D     4    11      6       8      6    10     6      2      6     10   \n",
       "3      N     7    11      6       6      3     5     9      4      6      4   \n",
       "4      G     2     1      3       1      1     8     6      6      6      6   \n",
       "\n",
       "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0      10       8      0       8      0       8  \n",
       "1       3       9      2       8      4      10  \n",
       "2       3       7      3       7      3       9  \n",
       "3       4      10      6      10      2       8  \n",
       "4       5       9      1       7      5      10  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/Users/kirtisailinaidu/Downloads/Neural networks/Alphabets_data.csv',encoding=\"latin-1\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1abbad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  word_count\n",
       "0      T           1\n",
       "1      I           1\n",
       "2      D           1\n",
       "3      N           1\n",
       "4      G           1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of Words in single tweet\n",
    "data['word_count'] = data['letter'].apply(lambda x: len(str(x).split(\" \")))\n",
    "data[['letter','word_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bb09eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  char_count\n",
       "0      T           1\n",
       "1      I           1\n",
       "2      D           1\n",
       "3      N           1\n",
       "4      G           1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of characters in single tweet\n",
    "data['char_count'] = data['letter'].str.len() ## this also includes spaces\n",
    "data[['letter','char_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf97e8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>avg_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  avg_word\n",
       "0      T       1.0\n",
       "1      I       1.0\n",
       "2      D       1.0\n",
       "3      N       1.0\n",
       "4      G       1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_word(sentence):\n",
    "  words = sentence.split()\n",
    "  return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "data['avg_word'] = data['letter'].apply(lambda x: avg_word(x))\n",
    "data[['letter','avg_word']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc49b8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  stopwords\n",
       "0      T          0\n",
       "1      I          0\n",
       "2      D          0\n",
       "3      N          0\n",
       "4      G          0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "\n",
    "data['stopwords'] = data['letter'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "data[['letter','stopwords']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e75f7219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>hastags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  hastags\n",
       "0      T        0\n",
       "1      I        0\n",
       "2      D        0\n",
       "3      N        0\n",
       "4      G        0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['hastags'] = data['letter'].apply(lambda x: len([x for x in x.split() if x.startswith('@')]))\n",
    "data[['letter','hastags']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f31c3f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>numerics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  numerics\n",
       "0      T         0\n",
       "1      I         0\n",
       "2      D         0\n",
       "3      N         0\n",
       "4      G         0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['numerics'] = data['letter'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "data[['letter','numerics']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34d2e3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  upper\n",
       "0      T      1\n",
       "1      I      1\n",
       "2      D      1\n",
       "3      N      1\n",
       "4      G      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['upper'] = data['letter'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "data[['letter','upper']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "984daa98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    t\n",
       "1    i\n",
       "2    d\n",
       "3    n\n",
       "4    g\n",
       "Name: letter, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['letter'] = data['letter'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "data['letter'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "321e95c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    t\n",
       "1    i\n",
       "2    d\n",
       "3    n\n",
       "4    g\n",
       "Name: letter, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['letter'] = data['letter'].str.replace('[^\\w\\s]','')\n",
    "data['letter'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39a451b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     \n",
       "1     \n",
       "2     \n",
       "3    n\n",
       "4    g\n",
       "Name: letter, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "data['letter'] = data['letter'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "data['letter'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84b6955c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u    813\n",
       "p    803\n",
       "x    787\n",
       "n    783\n",
       "q    783\n",
       "f    775\n",
       "g    773\n",
       "e    768\n",
       "b    766\n",
       "v    764\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(data['letter']).split()).value_counts()[:10]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ea3a987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \n",
       "1    \n",
       "2    \n",
       "3    \n",
       "4    \n",
       "Name: letter, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "data['letter'] = data['letter'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "data['letter'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41e52f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "l    761\n",
       "r    758\n",
       "w    752\n",
       "j    747\n",
       "k    739\n",
       "c    736\n",
       "h    734\n",
       "z    734\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(data['letter']).split()).value_counts()[-10:]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c082db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \n",
       "1    \n",
       "2    \n",
       "3    \n",
       "4    \n",
       "Name: letter, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "data['letter'] = data['letter'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "data['letter'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3248fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \n",
       "1    \n",
       "2    \n",
       "3    \n",
       "4    \n",
       "Name: letter, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['letter'][:5].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5aef2d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/kirtisailinaidu/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "words = TextBlob(data['letter'][1]).words\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2de9323a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList([])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(data['letter'][1]).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1faad72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \n",
       "1    \n",
       "2    \n",
       "3    \n",
       "4    \n",
       "Name: letter, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "data['letter'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b06ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baf9bcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \n",
       "1    \n",
       "2    \n",
       "3    \n",
       "4    \n",
       "Name: letter, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['letter'] = data['letter'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "data['letter'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c6f9a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(data['letter'][0]).ngrams(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdabb63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p0/vrfqq_vd7qs5cnv6g_1n5vnw0000gn/T/ipykernel_16612/4252847815.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tf1 = (data['letter'][1:2]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
      "/var/folders/p0/vrfqq_vd7qs5cnv6g_1n5vnw0000gn/T/ipykernel_16612/4252847815.py:1: FutureWarning: value_counts with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  tf1 = (data['letter'][1:2]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  words  tf\n",
       "0         1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1 = (data['letter'][1:2]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
    "tf1.columns = ['words','tf']\n",
    "tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38674317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  words  tf  idf\n",
       "0         1  0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i,word in enumerate(tf1['words']):\n",
    "  tf1.loc[i, 'idf'] = np.log(data.shape[0]/(len(data[data['letter'].str.contains(word)])))\n",
    "\n",
    "tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b56cda7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  words  tf  idf  tfidf\n",
       "0         1  0.0    0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1['tfidf'] = tf1['tf'] * tf1['idf']\n",
    "tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "396b0890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: letter, dtype: object)\n",
      "Error: empty vocabulary; perhaps the documents only contain stop words\n",
      "Trying with stop_words=None\n",
      "Error: empty vocabulary; perhaps the documents only contain stop words\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data['letter'] = data['letter'].fillna('').astype(str)\n",
    "data = data[data['letter'].str.strip() != '']\n",
    "\n",
    "print(data['letter'].head())\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word', stop_words='english', ngram_range=(1, 1))\n",
    "\n",
    "try:\n",
    "    vect = tfidf.fit_transform(data['letter'])\n",
    "    print(vect)\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    vect = None\n",
    "\n",
    "if vect is None or vect.shape[0] == 0:\n",
    "    print(\"Trying with stop_words=None\")\n",
    "    tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word', stop_words=None, ngram_range=(1, 1))\n",
    "    try:\n",
    "        vect = tfidf.fit_transform(data['letter'])\n",
    "        print(vect)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d063ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: letter, dtype: object)\n",
      "Error: empty vocabulary; perhaps the documents only contain stop words\n",
      "Trying with stop_words=None\n",
      "Error: empty vocabulary; perhaps the documents only contain stop words\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data['letter'] = data['letter'].fillna('').astype(str)\n",
    "data = data[data['letter'].str.strip() != '']\n",
    "\n",
    "print(data['letter'].head())\n",
    "\n",
    "bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1), analyzer='word', stop_words='english')\n",
    "\n",
    "try:\n",
    "    data_bow = bow.fit_transform(data['letter'])\n",
    "    print(data_bow)\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    data_bow = None\n",
    "\n",
    "if data_bow is None:\n",
    "    print(\"Trying with stop_words=None\")\n",
    "    bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1), analyzer='word', stop_words=None)\n",
    "    try:\n",
    "        data_bow = bow.fit_transform(data['letter'])\n",
    "        print(data_bow)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "744d4767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: letter, dtype: object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['letter'][:5].apply(lambda x: TextBlob(x).sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99a24784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [letter, sentiment]\n",
       "Index: []"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'] = data['letter'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "data[['letter','sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bded83e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: future in ./anaconda3/lib/python3.11/site-packages (0.18.3)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "991b9e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: future in ./anaconda3/lib/python3.11/site-packages (0.18.3)\n",
      "Collecting future\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: future\n",
      "  Attempting uninstall: future\n",
      "    Found existing installation: future 0.18.3\n",
      "    Uninstalling future-0.18.3:\n",
      "      Successfully uninstalled future-0.18.3\n",
      "Successfully installed future-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bcda43b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "import copy\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import matplotlib\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0118f439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "from nltk.corpus import twitter_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9408ae55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kirtisailinaidu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ab2ab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6087de33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/kirtisailinaidu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tweets sample:\n",
      "['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)', '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!', '@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!', '@97sides CONGRATS :)', 'yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark on my fb profile :) in 15 days']\n",
      "\n",
      "Negative tweets sample:\n",
      "['hopeless for tmr :(', \"Everything in the kids section of IKEA is so cute. Shame I'm nearly 19 in 2 months :(\", '@Hegelbon That heart sliding into the waste basket. :(', '“@ketchBurning: I hate Japanese call him \"bani\" :( :(”\\n\\nMe too', 'Dang starting next week I have \"work\" :(']\n",
      "\n",
      "Random tweets sample:\n",
      "['RT @KirkKus: Indirect cost of the UK being in the EU is estimated to be costing Britain £170 billion per year! #BetterOffOut #UKIP', 'VIDEO: Sturgeon on post-election deals http://t.co/BTJwrpbmOY', 'RT @LabourEoin: The economy was growing 3 times faster on the day David Cameron became Prime Minister than it is today.. #BBCqt http://t.co…', 'RT @GregLauder: the UKIP east lothian candidate looks about 16 and still has an msn addy http://t.co/7eIU0c5Fm1', \"RT @thesundaypeople: UKIP's housing spokesman rakes in £800k in housing benefit from migrants.  http://t.co/GVwb9Rcb4w http://t.co/c1AZxcLh…\"]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "# Download the twitter_samples corpus if not already downloaded\n",
    "nltk.download('twitter_samples')\n",
    "\n",
    "# Load the positive, negative, and other tweets from the twitter_samples corpus\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "text = twitter_samples.strings('tweets.20150430-223406.json')\n",
    "\n",
    "# Print a few samples for verification\n",
    "print(\"Positive tweets sample:\")\n",
    "print(positive_tweets[:5])\n",
    "\n",
    "print(\"\\nNegative tweets sample:\")\n",
    "print(negative_tweets[:5])\n",
    "\n",
    "print(\"\\nRandom tweets sample:\")\n",
    "print(text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "670af16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "text = twitter_samples.strings('tweets.20150430-223406.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "214f177f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/kirtisailinaidu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c42546d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "text = twitter_samples.strings('tweets.20150430-223406.json')\n",
    "tweet_tokens = twitter_samples.tokenized('positive_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e18caee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#FollowFriday\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "text = twitter_samples.strings('tweets.20150430-223406.json')\n",
    "tweet_tokens = twitter_samples.tokenized('positive_tweets.json')[0]\n",
    "\n",
    "print(tweet_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "28535dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in ./anaconda3/lib/python3.11/site-packages (4.12.2)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in ./anaconda3/lib/python3.11/site-packages (from beautifulsoup4) (2.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f047616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as ticker\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8e18d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_pages = 2\n",
    "\n",
    "def get_data(pageNo):  \n",
    "    headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "    r = requests.get('https://www.amazon.in/gp/bestsellers/books/ref=zg_bs_pg_'+str(pageNo)+'?ie=UTF8&pg='+str(pageNo), headers=headers)#, proxies=proxies)\n",
    "    content = r.content\n",
    "    soup = BeautifulSoup(content)\n",
    "    #print(soup)\n",
    "\n",
    "    alls = []\n",
    "    for d in soup.findAll('div', attrs={'class':'a-section a-spacing-none aok-relative'}):\n",
    "        #print(d)\n",
    "        name = d.find('span', attrs={'class':'zg-text-center-align'})\n",
    "        n = name.find_all('img', alt=True)\n",
    "        #print(n[0]['alt'])\n",
    "        author = d.find('a', attrs={'class':'a-size-small a-link-child'})\n",
    "        rating = d.find('span', attrs={'class':'a-icon-alt'})\n",
    "        users_rated = d.find('a', attrs={'class':'a-size-small a-link-normal'})\n",
    "        price = d.find('span', attrs={'class':'p13n-sc-price'})\n",
    "\n",
    "        all1=[]\n",
    "\n",
    "        if name is not None:\n",
    "            #print(n[0]['alt'])\n",
    "            all1.append(n[0]['alt'])\n",
    "        else:\n",
    "            all1.append(\"unknown-product\")\n",
    "\n",
    "        if author is not None:\n",
    "            #print(author.text)\n",
    "            all1.append(author.text)\n",
    "        elif author is None:\n",
    "            author = d.find('span', attrs={'class':'a-size-small a-color-base'})\n",
    "            if author is not None:\n",
    "                all1.append(author.text)\n",
    "            else:    \n",
    "                all1.append('0')\n",
    "\n",
    "        if rating is not None:\n",
    "            #print(rating.text)\n",
    "            all1.append(rating.text)\n",
    "        else:\n",
    "            all1.append('-1')\n",
    "\n",
    "        if users_rated is not None:\n",
    "            #print(price.text)\n",
    "            all1.append(users_rated.text)\n",
    "        else:\n",
    "            all1.append('0')     \n",
    "\n",
    "        if price is not None:\n",
    "            #print(price.text)\n",
    "            all1.append(price.text)\n",
    "        else:\n",
    "            all1.append('0')\n",
    "        alls.append(all1)    \n",
    "    return alls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a57f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(1, no_pages+1):\n",
    "    results.append(get_data(i))\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "df = pd.DataFrame(flatten(results),columns=['Book Name','Author','Rating','Customers_Rated', 'Price'])\n",
    "df.to_csv('/Users/kirtisailinaidu/Downloads/Neural networks/Alphabets_data.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
